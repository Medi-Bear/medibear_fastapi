import os
import joblib
import pandas as pd
import json
from dotenv import load_dotenv
from groq import Groq


APP_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
MODEL_DIR = os.path.join(APP_DIR, "models", "calorie")

MODEL_PATH = os.path.join(MODEL_DIR, "calorie_model.pkl")
SCALER_PATH = os.path.join(MODEL_DIR, "scaler.pkl")
ENCODER_PATH = os.path.join(MODEL_DIR, "encoder_dict.json")

# 1) ëª¨ë¸ ë¡œë“œ
model = joblib.load(MODEL_PATH)
scaler = joblib.load(SCALER_PATH)
with open(ENCODER_PATH, 'r') as f:
    encoder_dict = json.load(f)

# 2) í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# 3) Groq client ìƒì„±
groq_client = Groq(api_key=os.getenv("GROQ_API_KEY"))


# -----------------------------
# ğŸ”¥ ì¹¼ë¡œë¦¬ ì˜ˆì¸¡ í•¨ìˆ˜
# -----------------------------
def predict_calories(duration_minutes: float, weight_kg: float, activity_type: str, bmi: float):
    data = pd.DataFrame({
        'duration_minutes': [duration_minutes],
        'weight_kg': [weight_kg],
        'activity_type': [activity_type],
        'bmi': [bmi]
    })

    # activity_type ì¸ì½”ë”©
    if activity_type in encoder_dict['activity_type']:
        data['activity_type'] = [encoder_dict['activity_type'][activity_type]]
    else:
        data['activity_type'] = [encoder_dict['activity_type']['Unkown']]

    # ìŠ¤ì¼€ì¼ë§
    data_scaled = scaler.transform(data)

    # ì˜ˆì¸¡
    calorie_prediction = model.predict(data_scaled)[0]
    return round(float(calorie_prediction), 2)


# -----------------------------
# ğŸ”¥ Groq LLM ë¶„ì„ í•¨ìˆ˜
# -----------------------------
def llm_anaylze_calorie(logs):
    # compact log í¬ë§·íŒ…
    log_text = "\n".join(
        f"{l.activityType}/{int(l.caloriesBurned/8)}ë¶„/{l.caloriesBurned}kcal/{l.weightKg}kg"
        for l in logs
    )
    
    prompt = f"""
    ë°ì´í„°:
    {log_text}

    ì‘ë‹µ:
    1) ìš´ë™ íŒ¨í„´ ìš”ì•½ 
    2) ì¹¼ë¡œë¦¬ ì†Œëª¨ ì¶”ì„¸ 
    3) 15ì¼ í›„, 30ì¼ í›„ ëª¸ë¬´ê²Œ ì˜ˆì¸¡
    ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³  ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
    """

    # â­ Groq ëª¨ë¸ í˜¸ì¶œ (async)
    response = groq_client.chat.completions.create(
        messages=[{"role": "user", "content": prompt}],
        model="openai/gpt-oss-120b",   # ë¹ ë¥´ê³  í’ˆì§ˆ ì¢‹ìŒ
        temperature=0.3
    )

    advice = response.choices[0].message.content.strip()

    return {
        "prompt": prompt,
        "advice": advice
    }
